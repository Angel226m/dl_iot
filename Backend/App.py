''' 

import os
import cv2
import json
import numpy as np
import torch
import torch.nn.functional as F
from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
from werkzeug.utils import secure_filename
from pathlib import Path
import albumentations as A
from albumentations.pytorch import ToTensorV2
from transformers import SegformerForSemanticSegmentation
from datetime import datetime
import traceback
import base64

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURACIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

app = Flask(__name__)
# Configurar CORS para permitir todas las peticiones en desarrollo
CORS(app, resources={
    r"/api/*": {
        "origins": ["*"],
        "methods": ["GET", "POST", "OPTIONS"],
        "allow_headers": ["Content-Type"],
        "expose_headers": ["Content-Type"],
        "supports_credentials": False
    }
})

class Config:
    # Directorios
    UPLOAD_FOLDER = '/app/uploads'
    RESULTS_FOLDER = '/app/results'
    MODEL_PATH = os.getenv('MODEL_PATH', '/app/model/best_model.pth')
    
    # ConfiguraciÃ³n de archivos
    MAX_CONTENT_LENGTH = 20 * 1024 * 1024  # 20MB
    ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'bmp', 'tiff', 'tif'}
    
    # Modelo
    TARGET_SIZE = 640
    MODEL_NAME = "nvidia/segformer-b5-finetuned-ade-640-640"
    MEAN = [0.485, 0.456, 0.406]
    STD = [0.229, 0.224, 0.225]
    THRESHOLD = 0.5
    
    # TTA
    USE_TTA = True  # Activado por defecto para mejor calidad
    
    # Device
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

config = Config()
app.config['MAX_CONTENT_LENGTH'] = config.MAX_CONTENT_LENGTH

# Crear directorios
Path(config.UPLOAD_FOLDER).mkdir(exist_ok=True, parents=True)
Path(config.RESULTS_FOLDER).mkdir(exist_ok=True, parents=True)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CARGAR MODELO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

model = None

def cargar_modelo():
    """Carga el modelo SegFormer"""
    global model
    
    try:
        print(f"ğŸ¤– Cargando modelo desde: {config.MODEL_PATH}")
        
        # Cargar arquitectura
        model = SegformerForSemanticSegmentation.from_pretrained(
            config.MODEL_NAME,
            num_labels=1,
            ignore_mismatched_sizes=True
        )
        
        # Cargar pesos entrenados
        if os.path.exists(config.MODEL_PATH):
            checkpoint = torch.load(config.MODEL_PATH, map_location=config.DEVICE)
            
            if 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
            elif 'ema_state_dict' in checkpoint and checkpoint['ema_state_dict']:
                state_dict = checkpoint['ema_state_dict']
                print("   â„¹ï¸  Usando pesos EMA")
            else:
                state_dict = checkpoint
            
            model.load_state_dict(state_dict, strict=True)
            print(f"   âœ“ Modelo cargado exitosamente")
            
            if 'dice' in checkpoint:
                print(f"   âœ“ Dice: {checkpoint['dice']:.4f}")
        else:
            print(f"   âš ï¸  No se encontrÃ³ modelo en {config.MODEL_PATH}")
            print(f"   â„¹ï¸  Usando modelo base sin fine-tuning")
        
        model = model.to(config.DEVICE)
        model.eval()
        
        print(f"   âœ“ Device: {config.DEVICE}")
        print(f"   âœ“ ParÃ¡metros: {sum(p.numel() for p in model.parameters()):,}")
        print(f"   âœ“ TTA: {'ACTIVADO' if config.USE_TTA else 'DESACTIVADO'}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error cargando modelo: {e}")
        traceback.print_exc()
        return False

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# UTILIDADES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def allowed_file(filename):
    """Verifica si el archivo tiene extensiÃ³n permitida"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in config.ALLOWED_EXTENSIONS

def get_transform():
    """Transforma de preprocesamiento"""
    return A.Compose([
        A.Normalize(mean=config.MEAN, std=config.STD),
        ToTensorV2(),
    ])

def procesar_imagen(image_path):
    """Carga y preprocesa imagen"""
    img = cv2.imread(str(image_path))
    if img is None:
        raise ValueError(f"No se pudo cargar la imagen")
    
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img_resized = cv2.resize(img_rgb, (config.TARGET_SIZE, config.TARGET_SIZE))
    
    transform = get_transform()
    transformed = transform(image=img_resized)
    img_tensor = transformed['image'].unsqueeze(0)
    
    return img_tensor, img_rgb

def predecir_simple(img_tensor):
    """PredicciÃ³n simple sin TTA"""
    if model is None:
        raise RuntimeError("El modelo no estÃ¡ cargado")
    
    img_tensor = img_tensor.to(config.DEVICE)
    
    with torch.no_grad():
        outputs = model(pixel_values=img_tensor)
        logits = outputs.logits
        
        logits = F.interpolate(
            logits,
            size=(config.TARGET_SIZE, config.TARGET_SIZE),
            mode='bilinear',
            align_corners=False
        )
        
        pred = torch.sigmoid(logits)
        mask = pred.squeeze().cpu().numpy()
    
    return mask

def aplicar_tta(img_tensor):
    """
    Test-Time Augmentation para mejor precisiÃ³n
    Aplica 4 transformaciones y promedia los resultados
    """
    if model is None:
        raise RuntimeError("El modelo no estÃ¡ cargado")
    
    transformaciones = [
        ('original', lambda x: x, lambda x: x),
        ('hflip', lambda x: torch.flip(x, dims=[3]), lambda x: torch.flip(x, dims=[3])),
        ('vflip', lambda x: torch.flip(x, dims=[2]), lambda x: torch.flip(x, dims=[2])),
        ('rot90', lambda x: torch.rot90(x, k=1, dims=[2, 3]), lambda x: torch.rot90(x, k=3, dims=[2, 3])),
    ]
    
    preds = []
    
    for nombre, tfm_forward, tfm_backward in transformaciones:
        # Transformar entrada
        img_tfm = tfm_forward(img_tensor.clone())
        
        # Predecir
        with torch.no_grad():
            outputs = model(pixel_values=img_tfm.to(config.DEVICE))
            logits = outputs.logits
            
            logits = F.interpolate(
                logits,
                size=(config.TARGET_SIZE, config.TARGET_SIZE),
                mode='bilinear',
                align_corners=False
            )
            
            pred = torch.sigmoid(logits)
        
        # Revertir transformaciÃ³n
        pred = tfm_backward(pred)
        preds.append(pred)
    
    # Promediar todas las predicciones
    mask = torch.stack(preds).mean(dim=0).squeeze().cpu().numpy()
    
    return mask

def predecir(img_tensor, use_tta=True):
    """Realiza predicciÃ³n con o sin TTA"""
    if use_tta:
        return aplicar_tta(img_tensor)
    else:
        return predecir_simple(img_tensor)

def post_procesar(mask, threshold=0.5):
    """Post-procesamiento de mÃ¡scara"""
    mask_binary = (mask > threshold).astype(np.uint8)
    
    # Eliminar componentes pequeÃ±os (ruido)
    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask_binary, connectivity=8)
    
    result = np.zeros_like(mask_binary)
    for i in range(1, num_labels):
        area = stats[i, cv2.CC_STAT_AREA]
        if area >= 10:  # MÃ­nimo 10 pÃ­xeles
            result[labels == i] = 1
    
    # Cerrar pequeÃ±os gaps
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    result = cv2.morphologyEx(result, cv2.MORPH_CLOSE, kernel, iterations=1)
    
    return result.astype(np.float32)

def calcular_metricas(mask, threshold=0.5):
    """Calcula mÃ©tricas detalladas de la predicciÃ³n"""
    mask_binary = (mask > threshold).astype(np.uint8)
    
    total_pixeles = mask.size
    pixeles_positivos = mask_binary.sum()
    porcentaje_grietas = (pixeles_positivos / total_pixeles) * 100
    
    # AnÃ¡lisis de componentes conexas
    num_grietas, labels, stats, _ = cv2.connectedComponentsWithStats(mask_binary, connectivity=8)
    num_grietas -= 1  # Restar fondo
    
    if num_grietas > 0:
        areas = [stats[i, cv2.CC_STAT_AREA] for i in range(1, num_grietas + 1)]
        area_promedio = float(np.mean(areas))
        area_max = float(np.max(areas))
        area_min = float(np.min(areas))
    else:
        area_promedio = 0
        area_max = 0
        area_min = 0
    
    # Determinar severidad y estado
    if porcentaje_grietas < 1:
        severidad = "Baja"
        estado = "Sin Grietas Significativas"
        color = "success"
    elif porcentaje_grietas < 5:
        severidad = "Baja"
        estado = "Grietas Menores"
        color = "info"
    elif porcentaje_grietas < 15:
        severidad = "Media"
        estado = "Grietas Moderadas"
        color = "warning"
    else:
        severidad = "Alta"
        estado = "Grietas Severas"
        color = "danger"
    
    # Calcular confianza basada en mÃºltiples factores
    confianza = min(95.0, 85.0 + (porcentaje_grietas * 0.5))
    
    return {
        'total_pixeles': int(total_pixeles),
        'pixeles_con_grietas': int(pixeles_positivos),
        'porcentaje_grietas': round(float(porcentaje_grietas), 2),
        'num_grietas_detectadas': int(num_grietas),
        'area_promedio_grieta': round(area_promedio, 2),
        'area_max_grieta': round(area_max, 2),
        'area_min_grieta': round(area_min, 2),
        'severidad': severidad,
        'estado': estado,
        'color_severidad': color,
        'confianza': round(confianza, 1),
        'tta_usado': config.USE_TTA
    }

def crear_visualizacion(img_original, mask, threshold=0.5):
    """Crea visualizaciÃ³n overlay"""
    h, w = img_original.shape[:2]
    mask_resized = cv2.resize(mask, (w, h), interpolation=cv2.INTER_LINEAR)
    mask_binary = (mask_resized > threshold).astype(np.uint8) * 255
    
    # Crear colormap personalizado (rojo para grietas)
    mask_colored = np.zeros((h, w, 3), dtype=np.uint8)
    mask_colored[mask_binary > 127] = [255, 0, 0]  # Rojo puro
    
    # Crear overlay con transparencia
    overlay = img_original.copy()
    alpha = 0.6
    overlay[mask_binary > 127] = (
        overlay[mask_binary > 127] * (1 - alpha) + 
        mask_colored[mask_binary > 127] * alpha
    ).astype(np.uint8)
    
    # AÃ±adir contornos para mejor visualizaciÃ³n
    contours, _ = cv2.findContours(mask_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cv2.drawContours(overlay, contours, -1, (0, 255, 255), 2)  # Contorno amarillo
    
    return overlay  # â† SOLO retornar overlay

def imagen_a_base64(img_rgb):
    """Convierte imagen RGB a base64 para envÃ­o al frontend"""
    img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
    _, buffer = cv2.imencode('.png', img_bgr)
    img_base64 = base64.b64encode(buffer).decode('utf-8')
    return f"data:image/png;base64,{img_base64}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RUTAS API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.route('/health', methods=['GET'])
def health():
    """Health check"""
    return jsonify({
        'status': 'healthy',
        'model_loaded': model is not None,
        'device': str(config.DEVICE),
        'tta_enabled': config.USE_TTA,
        'timestamp': datetime.now().isoformat()
    }), 200
@app.route('/api/predict', methods=['POST'])
def predict():
    """Endpoint principal de predicciÃ³n con TTA"""
    try:
        # Validar modelo
        if model is None:
            return jsonify({'error': 'El modelo no estÃ¡ cargado'}), 503
        
        # Validar archivo
        if 'image' not in request.files:
            return jsonify({'error': 'No se enviÃ³ ninguna imagen'}), 400
        
        file = request.files['image']
        
        if file.filename == '':
            return jsonify({'error': 'Nombre de archivo vacÃ­o'}), 400
        
        if not allowed_file(file.filename):
            return jsonify({
                'error': 'Formato de archivo no permitido',
                'formatos_aceptados': list(config.ALLOWED_EXTENSIONS)
            }), 400
        
        # Obtener parÃ¡metros opcionales
        use_tta = request.form.get('use_tta', str(config.USE_TTA)).lower() == 'true'
        return_base64 = request.form.get('return_base64', 'true').lower() == 'true'  # â† Default true
        
        # Guardar archivo temporalmente
        filename = secure_filename(file.filename)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{timestamp}_{filename}"
        filepath = os.path.join(config.UPLOAD_FOLDER, filename)
        file.save(filepath)
        
        print(f"ğŸ“¥ Procesando: {filename}")
        print(f"   TTA: {use_tta}, Base64: {return_base64}")
        
        # Procesar imagen
        img_tensor, img_original = procesar_imagen(filepath)
        
        # Predecir con o sin TTA
        mask = predecir(img_tensor, use_tta=use_tta)
        
        # Post-procesar mÃ¡scara
        mask_procesada = post_procesar(mask, config.THRESHOLD)
        
        # Calcular mÃ©tricas detalladas
        metricas = calcular_metricas(mask_procesada, config.THRESHOLD)
        
        # Crear visualizaciÃ³n
        overlay = crear_visualizacion(img_original, mask_procesada, config.THRESHOLD)
        
        # Preparar respuesta
        response_data = {
            'success': True,
            'metricas': metricas,
            'timestamp': datetime.now().isoformat(),
            'procesamiento': {
                'tta_usado': use_tta,
                'threshold': config.THRESHOLD,
                'target_size': config.TARGET_SIZE
            }
        }
        
        # Devolver en base64 (por defecto) o guardar archivo
        if return_base64:
            # Convertir overlay a base64
            response_data['imagen_overlay'] = imagen_a_base64(overlay)
            print(f"âœ… Imagen en base64 generada (tamaÃ±o: {len(response_data['imagen_overlay'])} chars)")
        else:
            # Guardar archivo y devolver URL
            result_filename = f"result_{filename}"
            result_path = os.path.join(config.RESULTS_FOLDER, result_filename)
            overlay_bgr = cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR)
            cv2.imwrite(result_path, overlay_bgr)
        # âœ… CORREGIDO: NO incluir /api/, solo /results/
            response_data['result_image'] = f'/results/{result_filename}'
            print(f"âœ… Imagen guardada: {result_path}")
        
        
        # Eliminar archivo temporal
        os.remove(filepath)
        
        return jsonify(response_data), 200
        
    except Exception as e:
        print(f"âŒ Error en predicciÃ³n: {e}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500

@app.route('/api/batch_predict', methods=['POST'])
def batch_predict():
    """
    PredicciÃ³n en lote para mÃºltiples imÃ¡genes
    """
    try:
        if model is None:
            return jsonify({'error': 'El modelo no estÃ¡ cargado'}), 503
        
        if 'images' not in request.files:
            return jsonify({'error': 'No se enviaron imÃ¡genes'}), 400
        
        files = request.files.getlist('images')
        use_tta = request.form.get('use_tta', str(config.USE_TTA)).lower() == 'true'
        
        resultados = []
        
        for file in files:
            if file and allowed_file(file.filename):
                try:
                    # Procesar cada imagen
                    filename = secure_filename(file.filename)
                    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')
                    temp_filename = f"{timestamp}_{filename}"
                    filepath = os.path.join(config.UPLOAD_FOLDER, temp_filename)
                    file.save(filepath)
                    
                    img_tensor, img_original = procesar_imagen(filepath)
                    mask = predecir(img_tensor, use_tta=use_tta)
                    mask_procesada = post_procesar(mask, config.THRESHOLD)
                    metricas = calcular_metricas(mask_procesada, config.THRESHOLD)
                    
                    resultados.append({
                        'filename': file.filename,
                        'metricas': metricas,
                        'success': True
                    })
                    
                    os.remove(filepath)
                    
                except Exception as e:
                    resultados.append({
                        'filename': file.filename,
                        'error': str(e),
                        'success': False
                    })
        
        return jsonify({
            'success': True,
            'total_procesadas': len(resultados),
            'resultados': resultados,
            'timestamp': datetime.now().isoformat()
        }), 200
        
    except Exception as e:
        print(f"âŒ Error en batch prediction: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/results/<filename>', methods=['GET'])
def get_result(filename):
    """Obtener imagen de resultado"""
    try:
        filepath = os.path.join(config.RESULTS_FOLDER, filename)
        if os.path.exists(filepath):
            return send_file(filepath, mimetype='image/png')
        else:
            return jsonify({'error': 'Archivo no encontrado'}), 404
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/config', methods=['GET', 'POST'])
def config_endpoint():
    """Obtener o actualizar configuraciÃ³n"""
    if request.method == 'GET':
        return jsonify({
            'target_size': config.TARGET_SIZE,
            'threshold': config.THRESHOLD,
            'use_tta': config.USE_TTA,
            'device': str(config.DEVICE),
            'model_name': config.MODEL_NAME
        }), 200
    
    elif request.method == 'POST':
        data = request.get_json()
        
        if 'threshold' in data:
            config.THRESHOLD = float(data['threshold'])
        
        if 'use_tta' in data:
            config.USE_TTA = bool(data['use_tta'])
        
        return jsonify({
            'success': True,
            'config': {
                'threshold': config.THRESHOLD,
                'use_tta': config.USE_TTA
            }
        }), 200

@app.route('/api/status', methods=['GET'])
def status():
    """Estado detallado del sistema"""
    return jsonify({
        'system': 'CrackGuard Backend',
        'version': '2.0.0',
        'model': 'SegFormer B5',
        'device': str(config.DEVICE),
        'model_loaded': model is not None,
        'configuration': {
            'threshold': config.THRESHOLD,
            'target_size': config.TARGET_SIZE,
            'tta_enabled': config.USE_TTA,
            'max_file_size_mb': config.MAX_CONTENT_LENGTH / (1024 * 1024)
        },
        'timestamp': datetime.now().isoformat()
    }), 200

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INICIALIZACIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("â•" * 80)
print("ğŸš€ INICIALIZANDO CRACKGUARD BACKEND v2.0")
print("â•" * 80)

modelo_cargado = cargar_modelo()

if modelo_cargado:
    print("âœ… Sistema listo para inferencia")
else:
    print("âš ï¸  Servidor iniciado sin modelo entrenado")

print("â•" * 80)

if __name__ == '__main__':
    print("\nğŸ”§ Ejecutando con Flask development server")
    print("âš ï¸  Para producciÃ³n usar: gunicorn app:app --bind 0.0.0.0:5000")
    app.run(host='0.0.0.0', port=5000, debug=False)'''


"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸš€ API BACKEND CRACKGUARD v3.0 - SUPER ENSEMBLE + TTA
Sistema de inferencia con UNet++ EfficientNet-B8
Desarrollado por: Angel226m
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸš€ API BACKEND CRACKGUARD v3.1 - SUPER ENSEMBLE + TTA + ANÃLISIS MORFOLÃ“GICO
Sistema de inferencia con UNet++ EfficientNet-B8 + ClasificaciÃ³n de Grietas
Desarrollado por: Angel226m
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸš€ API BACKEND CRACKGUARD v3.1 - UNET++ B8 + TTA + ANÃLISIS MORFOLÃ“GICO
Sistema de inferencia con UNet++ EfficientNet-B8 + AnÃ¡lisis Inteligente
Desarrollado por: Angel226m
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
































'''

import os
import cv2
import numpy as np
import torch
from flask import Flask, request, jsonify
from flask_cors import CORS
from werkzeug.utils import secure_filename
from pathlib import Path
import albumentations as A
from albumentations.pytorch import ToTensorV2
import segmentation_models_pytorch as smp
from datetime import datetime
import traceback
import base64
from scipy.ndimage import binary_fill_holes
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURACIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

app = Flask(__name__)
CORS(app)

class Config:
    # Directorios
    UPLOAD_FOLDER = '/app/uploads'
    MODEL_PATH = os.getenv('MODEL_PATH', '/app/model/best_model.pth')
    
    # ConfiguraciÃ³n de archivos
    MAX_CONTENT_LENGTH = 20 * 1024 * 1024  # 20MB
    ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'bmp', 'tiff', 'tif'}
    
    # Modelo UNet++ EfficientNet-B8
    ARCHITECTURE = 'UnetPlusPlus'
    ENCODER = 'timm-efficientnet-b8'
    TARGET_SIZE = 640
    
    # NormalizaciÃ³n ImageNet
    MEAN = [0.485, 0.456, 0.406]
    STD = [0.229, 0.224, 0.225]
    
    # Threshold
    THRESHOLD = 0.5
    MIN_CRACK_COVERAGE = 0.25
    
    # TTA (Test-Time Augmentation)
    USE_TTA = True
    TTA_TRANSFORMS = ['original', 'hflip', 'vflip', 'rotate90', 'rotate180', 'rotate270']
    
    # Post-procesamiento
    USE_MORPHOLOGY = True
    USE_CONNECTED_COMPONENTS = True
    MIN_COMPONENT_SIZE = 20
    
    # Overlay
    OVERLAY_COLOR = 'red'
    OVERLAY_ALPHA = 0.4
    
    # AnÃ¡lisis morfolÃ³gico
    ANGLE_TOLERANCE = 15  # grados
    MIN_CRACK_LENGTH = 50  # pÃ­xeles
    
    # Device
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

config = Config()
app.config['MAX_CONTENT_LENGTH'] = config.MAX_CONTENT_LENGTH

# Crear directorios
Path(config.UPLOAD_FOLDER).mkdir(exist_ok=True, parents=True)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CARGAR MODELO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

model = None
model_loaded = False

def cargar_modelo():
    """Carga el modelo UNet++ EfficientNet-B8"""
    global model, model_loaded
    
    try:
        print(f"ğŸ¤– Cargando UNet++ {config.ENCODER}...")
        print(f"   ğŸ“ Ruta: {config.MODEL_PATH}")
        
        # Verificar archivo
        if not os.path.exists(config.MODEL_PATH):
            print(f"   âŒ Archivo no encontrado")
            return False
        
        file_size_mb = os.path.getsize(config.MODEL_PATH) / (1024 * 1024)
        print(f"   ğŸ“¦ TamaÃ±o: {file_size_mb:.2f} MB")
        
        # Crear modelo
        model = smp.UnetPlusPlus(
            encoder_name=config.ENCODER,
            encoder_weights=None,
            in_channels=3,
            classes=1,
            activation=None,
        )
        
        # Cargar checkpoint
        checkpoint = torch.load(config.MODEL_PATH, map_location=config.DEVICE, weights_only=False)
        
        # Detectar formato
        if isinstance(checkpoint, dict):
            if 'swa_model_state_dict' in checkpoint:
                state_dict = checkpoint['swa_model_state_dict']
                print(f"   âœ“ Usando pesos SWA")
            elif 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
                print(f"   âœ“ Usando model_state_dict")
            elif 'ema_state_dict' in checkpoint and checkpoint['ema_state_dict']:
                state_dict = checkpoint['ema_state_dict']
                print(f"   âœ“ Usando pesos EMA")
            else:
                state_dict = checkpoint
        else:
            state_dict = checkpoint
        
        # Cargar pesos
        model.load_state_dict(state_dict, strict=False)
        
        # Mostrar mÃ©tricas
        if isinstance(checkpoint, dict):
            if 'dice' in checkpoint:
                print(f"   ğŸ“Š Dice Score: {checkpoint['dice']:.4f}")
            if 'epoch' in checkpoint:
                print(f"   ğŸ“ˆ Ã‰poca: {checkpoint['epoch']}")
        
        model = model.to(config.DEVICE)
        model.eval()
        
        print(f"   âœ“ Device: {config.DEVICE}")
        print(f"   âœ“ ParÃ¡metros: {sum(p.numel() for p in model.parameters()):,}")
        print(f"   âœ“ TTA: {len(config.TTA_TRANSFORMS)}x")
        print(f"   âœ“ AnÃ¡lisis MorfolÃ³gico: ACTIVADO")
        
        model_loaded = True
        return True
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        traceback.print_exc()
        return False

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ANÃLISIS MORFOLÃ“GICO INTELIGENTE (POST-MODELO)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analizar_orientacion_grieta(contour):
    """
    Analiza la orientaciÃ³n de una grieta usando PCA y line fitting
    Retorna: Ã¡ngulo (0-180Â°), tipo (horizontal/vertical/diagonal/irregular)
    """
    if len(contour) < 5:
        return None, "indefinido"
    
    try:
        # Fitear lÃ­nea a los puntos del contorno usando regresiÃ³n
        [vx, vy, x, y] = cv2.fitLine(contour, cv2.DIST_L2, 0, 0.01, 0.01)
        
        # Calcular Ã¡ngulo en grados (0-180)
        angle = np.arctan2(vy, vx) * 180 / np.pi
        angle = angle[0] if isinstance(angle, np.ndarray) else angle
        
        # Normalizar a 0-180
        if angle < 0:
            angle += 180
        
        # Clasificar orientaciÃ³n segÃºn Ã¡ngulo
        if (angle < config.ANGLE_TOLERANCE) or (angle > 180 - config.ANGLE_TOLERANCE):
            tipo = "horizontal"
        elif (90 - config.ANGLE_TOLERANCE < angle < 90 + config.ANGLE_TOLERANCE):
            tipo = "vertical"
        elif (45 - config.ANGLE_TOLERANCE < angle < 45 + config.ANGLE_TOLERANCE) or \
             (135 - config.ANGLE_TOLERANCE < angle < 135 + config.ANGLE_TOLERANCE):
            tipo = "diagonal"
        else:
            tipo = "irregular"
        
        return float(angle), tipo
        
    except Exception as e:
        return None, "indefinido"

def clasificar_patron_global(contours, mask_binary):
    """
    Clasifica el patrÃ³n general de agrietamiento
    
    Patrones:
    - Horizontal: FlexiÃ³n, presiÃ³n lateral, empuje de tierra
    - Vertical: Cargas pesadas, asentamientos diferenciales
    - Diagonal/Escalera: Esfuerzos cortantes, movimiento de terreno
    - Ramificada/Mapa: ContracciÃ³n tÃ©rmica, retracciÃ³n superficial
    - Mixto: CombinaciÃ³n de factores
    """
    
    if len(contours) == 0:
        return {
            'patron': 'sin_grietas',
            'descripcion': 'No se detectaron grietas',
            'causa_probable': 'N/A',
            'severidad_ajuste': 1.0
        }
    
    # Analizar orientaciones
    orientaciones = []
    longitudes = []
    
    for contour in contours:
        length = cv2.arcLength(contour, False)
        
        if length < config.MIN_CRACK_LENGTH:
            continue
        
        angle, tipo = analizar_orientacion_grieta(contour)
        
        if angle is not None:
            orientaciones.append(tipo)
            longitudes.append(length)
    
    if not orientaciones:
        return {
            'patron': 'superficial',
            'descripcion': 'Grietas superficiales menores',
            'causa_probable': 'Desgaste superficial normal',
            'severidad_ajuste': 0.8
        }
    
    # Contar tipos de orientaciones
    tipo_counts = Counter(orientaciones)
    tipo_dominante = tipo_counts.most_common(1)[0][0]
    diversidad = len(tipo_counts)
    num_grietas = len(orientaciones)
    
    # Calcular ramificaciÃ³n (complejidad del patrÃ³n)
    num_componentes = len(contours)
    complejidad = num_componentes / max(num_grietas, 1)
    
    # ClasificaciÃ³n segÃºn patrÃ³n dominante
    if diversidad >= 3 or complejidad > 1.5:
        # PatrÃ³n ramificado/mapa (mÃºltiples direcciones)
        return {
            'patron': 'ramificada_mapa',
            'descripcion': 'PatrÃ³n tipo mapa/ramificado - TÃ­pico de contracciÃ³n tÃ©rmica',
            'causa_probable': 'Cambios tÃ©rmicos, secado, contracciÃ³n del material',
            'severidad_ajuste': 0.8,
            'recomendacion': 'Monitoreo periÃ³dico - Generalmente superficial'
        }
    
    elif tipo_dominante == "horizontal" and tipo_counts["horizontal"] / len(orientaciones) > 0.6:
        # Grietas horizontales dominantes
        return {
            'patron': 'horizontal',
            'descripcion': 'Grietas predominantemente horizontales',
            'causa_probable': 'FlexiÃ³n estructural, presiÃ³n lateral, empuje de tierra',
            'severidad_ajuste': 1.1,
            'recomendacion': 'InspecciÃ³n de muros de contenciÃ³n y cimentaciÃ³n'
        }
    
    elif tipo_dominante == "vertical" and tipo_counts["vertical"] / len(orientaciones) > 0.6:
        # Grietas verticales dominantes (MÃS CRÃTICO)
        return {
            'patron': 'vertical',
            'descripcion': 'Grietas predominantemente verticales - âš ï¸ CRÃTICO',
            'causa_probable': 'Cargas verticales excesivas, asentamientos diferenciales',
            'severidad_ajuste': 1.3,
            'recomendacion': 'âš ï¸ URGENTE: InspecciÃ³n estructural profesional inmediata'
        }
    
    elif tipo_dominante == "diagonal" and tipo_counts["diagonal"] / len(orientaciones) > 0.5:
        # Grietas diagonales (MUY CRÃTICO)
        return {
            'patron': 'diagonal_escalera',
            'descripcion': 'Grietas diagonales/en escalera - âš ï¸ MUY CRÃTICO',
            'causa_probable': 'Esfuerzos cortantes, movimiento del terreno, asentamientos irregulares',
            'severidad_ajuste': 1.4,
            'recomendacion': 'ğŸ”´ URGENTE: EvaluaciÃ³n estructural crÃ­tica - Posible falla inminente'
        }
    
    elif diversidad >= 2:
        # PatrÃ³n mixto
        return {
            'patron': 'mixto',
            'descripcion': 'PatrÃ³n mixto de agrietamiento',
            'causa_probable': 'CombinaciÃ³n de factores estructurales y ambientales',
            'severidad_ajuste': 1.2,
            'recomendacion': 'InspecciÃ³n profesional detallada requerida'
        }
    
    else:
        # PatrÃ³n irregular
        return {
            'patron': 'irregular',
            'descripcion': 'PatrÃ³n irregular - Requiere anÃ¡lisis detallado',
            'causa_probable': 'Causa indeterminada',
            'severidad_ajuste': 1.0,
            'recomendacion': 'Se recomienda inspecciÃ³n profesional'
        }

def analizar_morfologia_detallada(mask, contours):
    """
    AnÃ¡lisis morfolÃ³gico completo de las grietas
    """
    
    mask_binary = (mask > 127).astype(np.uint8)
    
    # Clasificar patrÃ³n global
    patron_info = clasificar_patron_global(contours, mask_binary)
    
    # Analizar grietas individuales
    grietas_detalle = []
    orientaciones_count = {
        "horizontal": 0,
        "vertical": 0,
        "diagonal": 0,
        "irregular": 0
    }
    
    for i, contour in enumerate(contours):
        length = cv2.arcLength(contour, False)
        
        if length < config.MIN_CRACK_LENGTH:
            continue
        
        area = cv2.contourArea(contour)
        angle, tipo = analizar_orientacion_grieta(contour)
        
        # Calcular ancho promedio
        width = area / length if length > 0 else 0
        
        # Bounding box
        x, y, w, h = cv2.boundingRect(contour)
        aspect_ratio = max(w, h) / min(w, h) if min(w, h) > 0 else 0
        
        orientaciones_count[tipo] += 1
        
        grietas_detalle.append({
            'id': i + 1,
            'longitud_px': round(float(length), 2),
            'area_px': int(area),
            'ancho_promedio_px': round(float(width), 2),
            'angulo_grados': round(angle, 1) if angle else None,
            'orientacion': tipo,
            'aspect_ratio': round(float(aspect_ratio), 2),
            'bbox': {
                'x': int(x),
                'y': int(y),
                'width': int(w),
                'height': int(h)
            }
        })
    
    # Ordenar por longitud (mÃ¡s largas primero)
    grietas_detalle.sort(key=lambda x: x['longitud_px'], reverse=True)
    
    return {
        'patron_general': patron_info['patron'],
        'descripcion_patron': patron_info['descripcion'],
        'causa_probable': patron_info['causa_probable'],
        'severidad_ajuste': patron_info['severidad_ajuste'],
        'recomendacion': patron_info.get('recomendacion', 'Monitoreo continuo'),
        'distribucion_orientaciones': orientaciones_count,
        'num_grietas_analizadas': len(grietas_detalle),
        'grietas_principales': grietas_detalle[:5]  # Top 5
    }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PROCESAMIENTO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_transform():
    return A.Compose([
        A.Resize(config.TARGET_SIZE, config.TARGET_SIZE, interpolation=cv2.INTER_CUBIC),
        A.Normalize(mean=config.MEAN, std=config.STD),
        ToTensorV2()
    ])

def advanced_postprocess(mask):
    """Post-procesamiento morfolÃ³gico + connected components"""
    mask_np = mask.cpu().numpy() if torch.is_tensor(mask) else mask
    
    if config.USE_MORPHOLOGY:
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        mask_np = cv2.morphologyEx(mask_np, cv2.MORPH_CLOSE, kernel)
        mask_np = cv2.morphologyEx(mask_np, cv2.MORPH_OPEN, kernel)
    
    if config.USE_CONNECTED_COMPONENTS:
        mask_binary = (mask_np > 0.5).astype(np.uint8)
        num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask_binary, connectivity=8)
        
        cleaned_mask = np.zeros_like(mask_np)
        for i in range(1, num_labels):
            if stats[i, cv2.CC_STAT_AREA] >= config.MIN_COMPONENT_SIZE:
                cleaned_mask[labels == i] = mask_np[labels == i]
        
        mask_np = cleaned_mask
    
    mask_binary = (mask_np > 0.5).astype(bool)
    mask_filled = binary_fill_holes(mask_binary)
    
    return mask_filled.astype(np.float32)

def predict_with_tta(model, img_tensor):
    """PredicciÃ³n con TTA (6 transformaciones)"""
    preds = []
    
    # Original
    with torch.no_grad():
        pred = model(img_tensor)
        pred = torch.sigmoid(pred)
        preds.append(pred)
    
    # Horizontal flip
    if 'hflip' in config.TTA_TRANSFORMS:
        img_hflip = torch.flip(img_tensor, dims=[3])
        with torch.no_grad():
            pred = model(img_hflip)
            pred = torch.sigmoid(pred)
            pred = torch.flip(pred, dims=[3])
            preds.append(pred)
    
    # Vertical flip
    if 'vflip' in config.TTA_TRANSFORMS:
        img_vflip = torch.flip(img_tensor, dims=[2])
        with torch.no_grad():
            pred = model(img_vflip)
            pred = torch.sigmoid(pred)
            pred = torch.flip(pred, dims=[2])
            preds.append(pred)
    
    # Rotate 90
    if 'rotate90' in config.TTA_TRANSFORMS:
        img_rot90 = torch.rot90(img_tensor, k=1, dims=[2, 3])
        with torch.no_grad():
            pred = model(img_rot90)
            pred = torch.sigmoid(pred)
            pred = torch.rot90(pred, k=-1, dims=[2, 3])
            preds.append(pred)
    
    # Rotate 180
    if 'rotate180' in config.TTA_TRANSFORMS:
        img_rot180 = torch.rot90(img_tensor, k=2, dims=[2, 3])
        with torch.no_grad():
            pred = model(img_rot180)
            pred = torch.sigmoid(pred)
            pred = torch.rot90(pred, k=-2, dims=[2, 3])
            preds.append(pred)
    
    # Rotate 270
    if 'rotate270' in config.TTA_TRANSFORMS:
        img_rot270 = torch.rot90(img_tensor, k=3, dims=[2, 3])
        with torch.no_grad():
            pred = model(img_rot270)
            pred = torch.sigmoid(pred)
            pred = torch.rot90(pred, k=-3, dims=[2, 3])
            preds.append(pred)
    
    return torch.stack(preds).mean(dim=0)

def procesar_imagen(image_path, use_tta=True):
    """Procesar imagen con el modelo"""
    if not model_loaded:
        raise RuntimeError("Modelo no cargado")
    
    # Cargar imagen
    img = cv2.imread(str(image_path))
    if img is None:
        raise ValueError("No se pudo cargar la imagen")
    
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    original_size = (img.shape[1], img.shape[0])
    
    # Preprocesar
    transform = get_transform()
    img_tensor = transform(image=img_rgb)['image'].unsqueeze(0).to(config.DEVICE)
    
    # PredicciÃ³n
    if use_tta:
        pred = predict_with_tta(model, img_tensor)
    else:
        with torch.no_grad():
            pred = model(img_tensor)
            pred = torch.sigmoid(pred)
    
    # Obtener confidence map
    confidence_map = pred.cpu().numpy()[0, 0]
    
    # Redimensionar
    confidence_map = cv2.resize(confidence_map, original_size, interpolation=cv2.INTER_LINEAR)
    
    # Post-procesamiento
    confidence_map = advanced_postprocess(torch.from_numpy(confidence_map))
    
    # MÃ¡scara binaria
    pred_mask = (confidence_map > config.THRESHOLD).astype(np.uint8) * 255
    
    return img_rgb, pred_mask, confidence_map

def crear_overlay(img_original, mask):
    """Crear overlay con toda la grieta coloreada"""
    mask_binary = (mask > 127).astype(np.uint8)
    
    # Crear mÃ¡scara de color
    color_mask = np.zeros_like(img_original)
    
    if config.OVERLAY_COLOR == 'red':
        color_mask[:, :, 0] = mask_binary * 255
    elif config.OVERLAY_COLOR == 'green':
        color_mask[:, :, 1] = mask_binary * 255
    elif config.OVERLAY_COLOR == 'yellow':
        color_mask[:, :, 0] = mask_binary * 255
        color_mask[:, :, 1] = mask_binary * 255
    else:
        color_mask[:, :, 0] = mask_binary * 255
    
    # Alpha blending
    overlay = cv2.addWeighted(img_original, 1.0, color_mask, config.OVERLAY_ALPHA, 0)
    
    return overlay

def calcular_metricas(mask, confidence_map):
    """Calcular mÃ©tricas + anÃ¡lisis morfolÃ³gico"""
    
    mask_binary = (mask > 127).astype(np.uint8)
    
    total_pixeles = mask.size
    pixeles_positivos = mask_binary.sum()
    porcentaje_grietas = (pixeles_positivos / total_pixeles) * 100
    
    # Contornos
    contours, _ = cv2.findContours(mask_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    num_contours = len(contours)
    
    if num_contours > 0:
        total_length = sum(cv2.arcLength(cnt, False) for cnt in contours)
        avg_length = total_length / num_contours
        max_length = max(cv2.arcLength(cnt, False) for cnt in contours)
        avg_width = pixeles_positivos / total_length if total_length > 0 else 0
    else:
        total_length = 0
        avg_length = 0
        max_length = 0
        avg_width = 0
    
    # ğŸ†• ANÃLISIS MORFOLÃ“GICO INTELIGENTE
    morfologia = analizar_morfologia_detallada(mask, contours)
    
    # Ajustar severidad segÃºn patrÃ³n
    severidad_ajuste = morfologia['severidad_ajuste']
    porcentaje_ajustado = porcentaje_grietas * severidad_ajuste
    
    # Severidad
    if porcentaje_ajustado < 1:
        severidad = "Baja"
        estado = "Sin Grietas Significativas"
    elif porcentaje_ajustado < 5:
        severidad = "Baja"
        estado = "Grietas Menores"
    elif porcentaje_ajustado < 15:
        severidad = "Media"
        estado = "Grietas Moderadas"
    else:
        severidad = "Alta"
        estado = "Grietas Severas"
    
    # Ajuste adicional por patrÃ³n crÃ­tico
    if morfologia['patron_general'] in ['vertical', 'diagonal_escalera']:
        if severidad == "Media":
            severidad = "Media-Alta"
        elif severidad == "Baja" and porcentaje_grietas > 2:
            severidad = "Media"
    
    confianza = min(95.0, 85.0 + (porcentaje_grietas * 0.5))
    
    return {
        'total_pixeles': int(total_pixeles),
        'pixeles_con_grietas': int(pixeles_positivos),
        'porcentaje_grietas': round(float(porcentaje_grietas), 2),
        'num_grietas_detectadas': int(num_contours),
        'longitud_total_px': float(total_length),
        'longitud_promedio_px': float(avg_length),
        'longitud_maxima_px': float(max_length),
        'ancho_promedio_px': float(avg_width),
        'severidad': severidad,
        'estado': estado,
        'confianza': round(confianza, 1),
        'confidence_max': float(confidence_map.max()),
        'confidence_mean': float(confidence_map.mean()),
        
        # ğŸ†• ANÃLISIS MORFOLÃ“GICO
        'analisis_morfologico': morfologia
    }

def imagen_a_base64(img_rgb):
    """Convertir imagen a base64"""
    img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
    _, buffer = cv2.imencode('.png', img_bgr)
    return f"data:image/png;base64,{base64.b64encode(buffer).decode('utf-8')}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RUTAS API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.route('/health', methods=['GET'])
def health():
    return jsonify({
        'status': 'healthy',
        'model_loaded': model_loaded,
        'architecture': f'{config.ARCHITECTURE} + {config.ENCODER}',
        'device': str(config.DEVICE),
        'tta_enabled': config.USE_TTA,
        'morphological_analysis': True,
        'timestamp': datetime.now().isoformat()
    }), 200

@app.route('/api/predict', methods=['POST'])
def predict():
    try:
        if not model_loaded:
            return jsonify({'error': 'Modelo no cargado'}), 503
        
        if 'image' not in request.files:
            return jsonify({'error': 'No se enviÃ³ imagen'}), 400
        
        file = request.files['image']
        
        if file.filename == '':
            return jsonify({'error': 'Nombre vacÃ­o'}), 400
        
        if not ('.' in file.filename and file.filename.rsplit('.', 1)[1].lower() in config.ALLOWED_EXTENSIONS):
            return jsonify({'error': 'Formato no permitido'}), 400
        
        # ParÃ¡metros
        use_tta = request.form.get('use_tta', 'true').lower() == 'true'
        
        # Guardar temporal
        filename = secure_filename(file.filename)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{timestamp}_{filename}"
        filepath = os.path.join(config.UPLOAD_FOLDER, filename)
        file.save(filepath)
        
        print(f"ğŸ“¥ Procesando: {filename} (TTA: {use_tta})")
        
        # Procesar
        img_original, pred_mask, confidence_map = procesar_imagen(filepath, use_tta)
        
        # Crear overlay
        overlay = crear_overlay(img_original, pred_mask)
        
        # MÃ©tricas + MorfologÃ­a
        metricas = calcular_metricas(pred_mask, confidence_map)
        
        morfologia = metricas['analisis_morfologico']
        print(f"   ğŸ” PatrÃ³n: {morfologia['patron_general']}")
        print(f"   ğŸ“ Orientaciones: {morfologia['distribucion_orientaciones']}")
        print(f"   âš ï¸  Severidad: {metricas['severidad']}")
        
        # Respuesta
        response_data = {
            'success': True,
            'metricas': metricas,
            'imagen_overlay': imagen_a_base64(overlay),
            'timestamp': datetime.now().isoformat(),
            'procesamiento': {
                'architecture': config.ARCHITECTURE,
                'encoder': config.ENCODER,
                'tta_usado': use_tta,
                'tta_transforms': len(config.TTA_TRANSFORMS) if use_tta else 0,
                'threshold': config.THRESHOLD,
                'target_size': config.TARGET_SIZE,
                'morphological_analysis': True,
            }
        }
        
        # Limpiar
        os.remove(filepath)
        
        return jsonify(response_data), 200
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INICIALIZACIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("â•" * 100)
print("ğŸš€ CRACKGUARD BACKEND v3.1 - UNET++ B8 + TTA + ANÃLISIS MORFOLÃ“GICO")
print("   AnÃ¡lisis Inteligente de OrientaciÃ³n POST-Modelo")
print("â•" * 100)

if cargar_modelo():
    print("âœ… Sistema listo para inferencia con anÃ¡lisis morfolÃ³gico")
else:
    print("âš ï¸  Servidor iniciado sin modelo")

print("â•" * 100)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=False)'''




"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸš€ API BACKEND CRACKGUARD v3.2 - UNET++ B8 + TTA + ANÃLISIS MORFOLÃ“GICO COMPLETO
Sistema de inferencia con detecciÃ³n de grietas ultra sensible
Desarrollado por: Angel226m
Fecha: 2025-10-27
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import cv2
import numpy as np
import torch
from flask import Flask, request, jsonify
from flask_cors import CORS
from werkzeug.utils import secure_filename
from pathlib import Path
import albumentations as A
from albumentations.pytorch import ToTensorV2
import segmentation_models_pytorch as smp
from datetime import datetime
import traceback
import base64
from scipy.ndimage import binary_fill_holes
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURACIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

app = Flask(__name__)
CORS(app)

class Config:
    # Directorios
    UPLOAD_FOLDER = '/app/uploads'
    MODEL_PATH = os.getenv('MODEL_PATH', '/app/model/best_model.pth')
    
    # ConfiguraciÃ³n de archivos
    MAX_CONTENT_LENGTH = 20 * 1024 * 1024  # 20MB
    ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'bmp', 'tiff', 'tif'}
    
    # Modelo UNet++ EfficientNet-B8
    ARCHITECTURE = 'UnetPlusPlus'
    ENCODER = 'timm-efficientnet-b8'
    TARGET_SIZE = 640
    
    # NormalizaciÃ³n ImageNet
    MEAN = [0.485, 0.456, 0.406]
    STD = [0.229, 0.224, 0.225]
    
    # Threshold
    THRESHOLD = 0.5
    MIN_CRACK_COVERAGE = 0.25
    
    # TTA (Test-Time Augmentation)
    USE_TTA = True
    TTA_TRANSFORMS = ['original', 'hflip', 'vflip', 'rotate90', 'rotate180', 'rotate270']
    
    # Post-procesamiento
    USE_MORPHOLOGY = True
    USE_CONNECTED_COMPONENTS = True
    MIN_COMPONENT_SIZE = 10  # âœ… REDUCIDO de 20 a 10 pÃ­xeles
    
    # Overlay
    OVERLAY_COLOR = 'red'
    OVERLAY_ALPHA = 0.4
    
    # AnÃ¡lisis morfolÃ³gico (ULTRA SENSIBLE)
    ANGLE_TOLERANCE = 15  # grados
    MIN_CRACK_LENGTH = 15  # âœ… REDUCIDO de 50 a 15 pÃ­xeles (detecta grietas MUY pequeÃ±as)
    
    # Device
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

config = Config()
app.config['MAX_CONTENT_LENGTH'] = config.MAX_CONTENT_LENGTH

# Crear directorios
Path(config.UPLOAD_FOLDER).mkdir(exist_ok=True, parents=True)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CARGAR MODELO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

model = None
model_loaded = False

def cargar_modelo():
    """Carga el modelo UNet++ EfficientNet-B8"""
    global model, model_loaded
    
    try:
        print(f"ğŸ¤– Cargando UNet++ {config.ENCODER}...")
        print(f"   ğŸ“ Ruta: {config.MODEL_PATH}")
        
        if not os.path.exists(config.MODEL_PATH):
            print(f"   âŒ Archivo no encontrado")
            return False
        
        file_size_mb = os.path.getsize(config.MODEL_PATH) / (1024 * 1024)
        print(f"   ğŸ“¦ TamaÃ±o: {file_size_mb:.2f} MB")
        
        model = smp.UnetPlusPlus(
            encoder_name=config.ENCODER,
            encoder_weights=None,
            in_channels=3,
            classes=1,
            activation=None,
        )
        
        checkpoint = torch.load(config.MODEL_PATH, map_location=config.DEVICE, weights_only=False)
        
        if isinstance(checkpoint, dict):
            if 'swa_model_state_dict' in checkpoint:
                state_dict = checkpoint['swa_model_state_dict']
                print(f"   âœ“ Usando pesos SWA")
            elif 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
                print(f"   âœ“ Usando model_state_dict")
            elif 'ema_state_dict' in checkpoint and checkpoint['ema_state_dict']:
                state_dict = checkpoint['ema_state_dict']
                print(f"   âœ“ Usando pesos EMA")
            else:
                state_dict = checkpoint
        else:
            state_dict = checkpoint
        
        model.load_state_dict(state_dict, strict=False)
        
        if isinstance(checkpoint, dict):
            if 'dice' in checkpoint:
                print(f"   ğŸ“Š Dice Score: {checkpoint['dice']:.4f}")
            if 'epoch' in checkpoint:
                print(f"   ğŸ“ˆ Ã‰poca: {checkpoint['epoch']}")
        
        model = model.to(config.DEVICE)
        model.eval()
        
        print(f"   âœ“ Device: {config.DEVICE}")
        print(f"   âœ“ ParÃ¡metros: {sum(p.numel() for p in model.parameters()):,}")
        print(f"   âœ“ TTA: {len(config.TTA_TRANSFORMS)}x")
        print(f"   âœ“ AnÃ¡lisis MorfolÃ³gico: ULTRA SENSIBLE (min {config.MIN_CRACK_LENGTH}px)")
        
        model_loaded = True
        return True
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        traceback.print_exc()
        return False

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ANÃLISIS MORFOLÃ“GICO INTELIGENTE (ULTRA SENSIBLE)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analizar_orientacion_grieta(contour):
    """
    Analiza la orientaciÃ³n de una grieta usando line fitting
    Retorna: Ã¡ngulo (0-180Â°), tipo (horizontal/vertical/diagonal/irregular)
    """
    if len(contour) < 5:
        return None, "indefinido"
    
    try:
        [vx, vy, x, y] = cv2.fitLine(contour, cv2.DIST_L2, 0, 0.01, 0.01)
        
        angle = np.arctan2(vy, vx) * 180 / np.pi
        angle = angle[0] if isinstance(angle, np.ndarray) else angle
        
        if angle < 0:
            angle += 180
        
        if (angle < config.ANGLE_TOLERANCE) or (angle > 180 - config.ANGLE_TOLERANCE):
            tipo = "horizontal"
        elif (90 - config.ANGLE_TOLERANCE < angle < 90 + config.ANGLE_TOLERANCE):
            tipo = "vertical"
        elif (45 - config.ANGLE_TOLERANCE < angle < 45 + config.ANGLE_TOLERANCE) or \
             (135 - config.ANGLE_TOLERANCE < angle < 135 + config.ANGLE_TOLERANCE):
            tipo = "diagonal"
        else:
            tipo = "irregular"
        
        return float(angle), tipo
        
    except Exception:
        return None, "indefinido"

def clasificar_patron_global(contours, mask_binary):
    """
    Clasifica el patrÃ³n general de agrietamiento (ULTRA SENSIBLE)
    """
    
    if len(contours) == 0:
        return {
            'patron': 'sin_grietas',
            'descripcion': 'No se detectaron grietas',
            'causa_probable': 'N/A',
            'severidad_ajuste': 1.0,
            'recomendacion': 'Estructura sin daÃ±os aparentes'
        }
    
    orientaciones = []
    longitudes = []
    
    for contour in contours:
        length = cv2.arcLength(contour, False)
        
        # âœ… UMBRAL ULTRA BAJO para detectar grietas pequeÃ±as
        if length < config.MIN_CRACK_LENGTH:
            continue
        
        angle, tipo = analizar_orientacion_grieta(contour)
        
        if angle is not None:
            orientaciones.append(tipo)
            longitudes.append(length)
    
    if not orientaciones:
        return {
            'patron': 'superficial',
            'descripcion': 'Grietas superficiales menores',
            'causa_probable': 'Desgaste superficial normal',
            'severidad_ajuste': 0.8,
            'recomendacion': 'Monitoreo periÃ³dico recomendado'
        }
    
    tipo_counts = Counter(orientaciones)
    tipo_dominante = tipo_counts.most_common(1)[0][0]
    diversidad = len(tipo_counts)
    num_grietas = len(orientaciones)
    
    num_componentes = len(contours)
    complejidad = num_componentes / max(num_grietas, 1)
    
    # ClasificaciÃ³n segÃºn patrÃ³n dominante
    if diversidad >= 3 or complejidad > 1.5:
        return {
            'patron': 'ramificada_mapa',
            'descripcion': 'PatrÃ³n tipo mapa/ramificado - TÃ­pico de contracciÃ³n tÃ©rmica',
            'causa_probable': 'Cambios tÃ©rmicos, secado, contracciÃ³n del material',
            'severidad_ajuste': 0.8,
            'recomendacion': 'Monitoreo periÃ³dico - Generalmente superficial'
        }
    
    elif tipo_dominante == "horizontal" and tipo_counts["horizontal"] / len(orientaciones) > 0.6:
        return {
            'patron': 'horizontal',
            'descripcion': 'Grietas predominantemente horizontales',
            'causa_probable': 'FlexiÃ³n estructural, presiÃ³n lateral, empuje de tierra',
            'severidad_ajuste': 1.1,
            'recomendacion': 'InspecciÃ³n de muros de contenciÃ³n y cimentaciÃ³n'
        }
    
    elif tipo_dominante == "vertical" and tipo_counts["vertical"] / len(orientaciones) > 0.6:
        return {
            'patron': 'vertical',
            'descripcion': 'Grietas predominantemente verticales - âš ï¸ CRÃTICO',
            'causa_probable': 'Cargas verticales excesivas, asentamientos diferenciales',
            'severidad_ajuste': 1.3,
            'recomendacion': 'âš ï¸ URGENTE: InspecciÃ³n estructural profesional inmediata'
        }
    
    elif tipo_dominante == "diagonal" and tipo_counts["diagonal"] / len(orientaciones) > 0.5:
        return {
            'patron': 'diagonal_escalera',
            'descripcion': 'Grietas diagonales/en escalera - âš ï¸ MUY CRÃTICO',
            'causa_probable': 'Esfuerzos cortantes, movimiento del terreno, asentamientos irregulares',
            'severidad_ajuste': 1.4,
            'recomendacion': 'ğŸ”´ URGENTE: EvaluaciÃ³n estructural crÃ­tica - Posible falla inminente'
        }
    
    elif diversidad >= 2:
        return {
            'patron': 'mixto',
            'descripcion': 'PatrÃ³n mixto de agrietamiento',
            'causa_probable': 'CombinaciÃ³n de factores estructurales y ambientales',
            'severidad_ajuste': 1.2,
            'recomendacion': 'InspecciÃ³n profesional detallada requerida'
        }
    
    else:
        return {
            'patron': 'irregular',
            'descripcion': 'PatrÃ³n irregular - Requiere anÃ¡lisis detallado',
            'causa_probable': 'Causa indeterminada',
            'severidad_ajuste': 1.0,
            'recomendacion': 'Se recomienda inspecciÃ³n profesional'
        }

def analizar_morfologia_detallada(mask, contours):
    """
    AnÃ¡lisis morfolÃ³gico completo (ULTRA SENSIBLE - detecta grietas pequeÃ±as)
    """
    
    mask_binary = (mask > 127).astype(np.uint8)
    patron_info = clasificar_patron_global(contours, mask_binary)
    
    grietas_detalle = []
    orientaciones_count = {
        "horizontal": 0,
        "vertical": 0,
        "diagonal": 0,
        "irregular": 0
    }
    
    for i, contour in enumerate(contours):
        length = cv2.arcLength(contour, False)
        
        # âœ… ANALIZA INCLUSO GRIETAS MUY PEQUEÃ‘AS (>= 15px)
        if length < config.MIN_CRACK_LENGTH:
            continue
        
        area = cv2.contourArea(contour)
        angle, tipo = analizar_orientacion_grieta(contour)
        
        width = area / length if length > 0 else 0
        
        x, y, w, h = cv2.boundingRect(contour)
        aspect_ratio = max(w, h) / min(w, h) if min(w, h) > 0 else 0
        
        orientaciones_count[tipo] += 1
        
        grietas_detalle.append({
            'id': i + 1,
            'longitud_px': round(float(length), 2),
            'area_px': int(area),
            'ancho_promedio_px': round(float(width), 2),
            'angulo_grados': round(angle, 1) if angle else None,
            'orientacion': tipo,
            'aspect_ratio': round(float(aspect_ratio), 2),
            'bbox': {
                'x': int(x),
                'y': int(y),
                'width': int(w),
                'height': int(h)
            }
        })
    
    grietas_detalle.sort(key=lambda x: x['longitud_px'], reverse=True)
    
    return {
        'patron_general': patron_info['patron'],
        'descripcion_patron': patron_info['descripcion'],
        'causa_probable': patron_info['causa_probable'],
        'severidad_ajuste': patron_info['severidad_ajuste'],
        'recomendacion': patron_info.get('recomendacion', 'Monitoreo continuo'),
        'distribucion_orientaciones': orientaciones_count,
        'num_grietas_analizadas': len(grietas_detalle),
        'grietas_principales': grietas_detalle[:5]
    }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PROCESAMIENTO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_transform():
    return A.Compose([
        A.Resize(config.TARGET_SIZE, config.TARGET_SIZE, interpolation=cv2.INTER_CUBIC),
        A.Normalize(mean=config.MEAN, std=config.STD),
        ToTensorV2()
    ])

def advanced_postprocess(mask):
    """Post-procesamiento morfolÃ³gico + connected components (SENSIBLE)"""
    mask_np = mask.cpu().numpy() if torch.is_tensor(mask) else mask
    
    if config.USE_MORPHOLOGY:
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        mask_np = cv2.morphologyEx(mask_np, cv2.MORPH_CLOSE, kernel)
        mask_np = cv2.morphologyEx(mask_np, cv2.MORPH_OPEN, kernel)
    
    if config.USE_CONNECTED_COMPONENTS:
        mask_binary = (mask_np > 0.5).astype(np.uint8)
        num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask_binary, connectivity=8)
        
        cleaned_mask = np.zeros_like(mask_np)
        for i in range(1, num_labels):
            # âœ… COMPONENTE MÃNIMO REDUCIDO (10px)
            if stats[i, cv2.CC_STAT_AREA] >= config.MIN_COMPONENT_SIZE:
                cleaned_mask[labels == i] = mask_np[labels == i]
        
        mask_np = cleaned_mask
    
    mask_binary = (mask_np > 0.5).astype(bool)
    mask_filled = binary_fill_holes(mask_binary)
    
    return mask_filled.astype(np.float32)

def predict_with_tta(model, img_tensor):
    """PredicciÃ³n con TTA (6 transformaciones)"""
    preds = []
    
    with torch.no_grad():
        pred = model(img_tensor)
        pred = torch.sigmoid(pred)
        preds.append(pred)
    
    if 'hflip' in config.TTA_TRANSFORMS:
        img_hflip = torch.flip(img_tensor, dims=[3])
        with torch.no_grad():
            pred = model(img_hflip)
            pred = torch.sigmoid(pred)
            pred = torch.flip(pred, dims=[3])
            preds.append(pred)
    
    if 'vflip' in config.TTA_TRANSFORMS:
        img_vflip = torch.flip(img_tensor, dims=[2])
        with torch.no_grad():
            pred = model(img_vflip)
            pred = torch.sigmoid(pred)
            pred = torch.flip(pred, dims=[2])
            preds.append(pred)
    
    if 'rotate90' in config.TTA_TRANSFORMS:
        img_rot90 = torch.rot90(img_tensor, k=1, dims=[2, 3])
        with torch.no_grad():
            pred = model(img_rot90)
            pred = torch.sigmoid(pred)
            pred = torch.rot90(pred, k=-1, dims=[2, 3])
            preds.append(pred)
    
    if 'rotate180' in config.TTA_TRANSFORMS:
        img_rot180 = torch.rot90(img_tensor, k=2, dims=[2, 3])
        with torch.no_grad():
            pred = model(img_rot180)
            pred = torch.sigmoid(pred)
            pred = torch.rot90(pred, k=-2, dims=[2, 3])
            preds.append(pred)
    
    if 'rotate270' in config.TTA_TRANSFORMS:
        img_rot270 = torch.rot90(img_tensor, k=3, dims=[2, 3])
        with torch.no_grad():
            pred = model(img_rot270)
            pred = torch.sigmoid(pred)
            pred = torch.rot90(pred, k=-3, dims=[2, 3])
            preds.append(pred)
    
    return torch.stack(preds).mean(dim=0)

def procesar_imagen(image_path, use_tta=True):
    """Procesar imagen con el modelo"""
    if not model_loaded:
        raise RuntimeError("Modelo no cargado")
    
    img = cv2.imread(str(image_path))
    if img is None:
        raise ValueError("No se pudo cargar la imagen")
    
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    original_size = (img.shape[1], img.shape[0])
    
    transform = get_transform()
    img_tensor = transform(image=img_rgb)['image'].unsqueeze(0).to(config.DEVICE)
    
    if use_tta:
        pred = predict_with_tta(model, img_tensor)
    else:
        with torch.no_grad():
            pred = model(img_tensor)
            pred = torch.sigmoid(pred)
    
    confidence_map = pred.cpu().numpy()[0, 0]
    confidence_map = cv2.resize(confidence_map, original_size, interpolation=cv2.INTER_LINEAR)
    confidence_map = advanced_postprocess(torch.from_numpy(confidence_map))
    pred_mask = (confidence_map > config.THRESHOLD).astype(np.uint8) * 255
    
    return img_rgb, pred_mask, confidence_map

def crear_overlay(img_original, mask):
    """Crear overlay con toda la grieta coloreada"""
    mask_binary = (mask > 127).astype(np.uint8)
    color_mask = np.zeros_like(img_original)
    
    if config.OVERLAY_COLOR == 'red':
        color_mask[:, :, 0] = mask_binary * 255
    elif config.OVERLAY_COLOR == 'green':
        color_mask[:, :, 1] = mask_binary * 255
    elif config.OVERLAY_COLOR == 'yellow':
        color_mask[:, :, 0] = mask_binary * 255
        color_mask[:, :, 1] = mask_binary * 255
    else:
        color_mask[:, :, 0] = mask_binary * 255
    
    overlay = cv2.addWeighted(img_original, 1.0, color_mask, config.OVERLAY_ALPHA, 0)
    return overlay

def calcular_metricas(mask, confidence_map):
    """Calcular mÃ©tricas + anÃ¡lisis morfolÃ³gico ULTRA SENSIBLE"""
    
    mask_binary = (mask > 127).astype(np.uint8)
    
    total_pixeles = mask.size
    pixeles_positivos = mask_binary.sum()
    porcentaje_grietas = (pixeles_positivos / total_pixeles) * 100
    
    contours, _ = cv2.findContours(mask_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    num_contours = len(contours)
    
    if num_contours > 0:
        total_length = sum(cv2.arcLength(cnt, False) for cnt in contours)
        avg_length = total_length / num_contours
        max_length = max(cv2.arcLength(cnt, False) for cnt in contours)
        avg_width = pixeles_positivos / total_length if total_length > 0 else 0
    else:
        total_length = 0
        avg_length = 0
        max_length = 0
        avg_width = 0
    
    # âœ… ANÃLISIS MORFOLÃ“GICO ULTRA SENSIBLE
    morfologia = analizar_morfologia_detallada(mask, contours)
    
    severidad_ajuste = morfologia['severidad_ajuste']
    porcentaje_ajustado = porcentaje_grietas * severidad_ajuste
    
    if porcentaje_ajustado < 1:
        severidad = "Baja"
        estado = "Sin Grietas Significativas"
    elif porcentaje_ajustado < 5:
        severidad = "Baja"
        estado = "Grietas Menores"
    elif porcentaje_ajustado < 15:
        severidad = "Media"
        estado = "Grietas Moderadas"
    else:
        severidad = "Alta"
        estado = "Grietas Severas"
    
    if morfologia['patron_general'] in ['vertical', 'diagonal_escalera']:
        if severidad == "Media":
            severidad = "Media-Alta"
        elif severidad == "Baja" and porcentaje_grietas > 2:
            severidad = "Media"
    
    confianza = min(95.0, 85.0 + (porcentaje_grietas * 0.5))
    
    return {
        'total_pixeles': int(total_pixeles),
        'pixeles_con_grietas': int(pixeles_positivos),
        'porcentaje_grietas': round(float(porcentaje_grietas), 2),
        'num_grietas_detectadas': int(num_contours),
        'longitud_total_px': float(total_length),
        'longitud_promedio_px': float(avg_length),
        'longitud_maxima_px': float(max_length),
        'ancho_promedio_px': float(avg_width),
        'severidad': severidad,
        'estado': estado,
        'confianza': round(confianza, 1),
        'confidence_max': float(confidence_map.max()),
        'confidence_mean': float(confidence_map.mean()),
        'analisis_morfologico': morfologia
    }

def imagen_a_base64(img_rgb):
    """Convertir imagen a base64"""
    img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
    _, buffer = cv2.imencode('.png', img_bgr)
    return f"data:image/png;base64,{base64.b64encode(buffer).decode('utf-8')}"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RUTAS API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.route('/health', methods=['GET'])
def health():
    return jsonify({
        'status': 'healthy',
        'model_loaded': model_loaded,
        'architecture': f'{config.ARCHITECTURE} + {config.ENCODER}',
        'device': str(config.DEVICE),
        'tta_enabled': config.USE_TTA,
        'morphological_analysis': True,
        'min_crack_length': config.MIN_CRACK_LENGTH,
        'timestamp': datetime.now().isoformat()
    }), 200

@app.route('/api/predict', methods=['POST'])
def predict():
    try:
        if not model_loaded:
            return jsonify({'error': 'Modelo no cargado'}), 503
        
        if 'image' not in request.files:
            return jsonify({'error': 'No se enviÃ³ imagen'}), 400
        
        file = request.files['image']
        
        if file.filename == '':
            return jsonify({'error': 'Nombre vacÃ­o'}), 400
        
        if not ('.' in file.filename and file.filename.rsplit('.', 1)[1].lower() in config.ALLOWED_EXTENSIONS):
            return jsonify({'error': 'Formato no permitido'}), 400
        
        use_tta = request.form.get('use_tta', 'true').lower() == 'true'
        
        filename = secure_filename(file.filename)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{timestamp}_{filename}"
        filepath = os.path.join(config.UPLOAD_FOLDER, filename)
        file.save(filepath)
        
        print(f"ğŸ“¥ Procesando: {filename} (TTA: {use_tta})")
        
        img_original, pred_mask, confidence_map = procesar_imagen(filepath, use_tta)
        overlay = crear_overlay(img_original, pred_mask)
        metricas = calcular_metricas(pred_mask, confidence_map)
        
        morfologia = metricas['analisis_morfologico']
        print(f"   ğŸ” PatrÃ³n: {morfologia['patron_general']}")
        print(f"   ğŸ“ Orientaciones: {morfologia['distribucion_orientaciones']}")
        print(f"   âš ï¸  Severidad: {metricas['severidad']}")
        print(f"   ğŸ“Š Grietas analizadas: {morfologia['num_grietas_analizadas']}")
        
        response_data = {
            'success': True,
            'metricas': metricas,
            'imagen_overlay': imagen_a_base64(overlay),
            'timestamp': datetime.now().isoformat(),
            'procesamiento': {
                'architecture': config.ARCHITECTURE,
                'encoder': config.ENCODER,
                'tta_usado': use_tta,
                'tta_transforms': len(config.TTA_TRANSFORMS) if use_tta else 0,
                'threshold': config.THRESHOLD,
                'target_size': config.TARGET_SIZE,
                'morphological_analysis': True,
                'min_crack_length': config.MIN_CRACK_LENGTH,
            }
        }
        
        os.remove(filepath)
        
        return jsonify(response_data), 200
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INICIALIZACIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("â•" * 100)
print("ğŸš€ CRACKGUARD BACKEND v3.2 - UNET++ B8 + TTA + ANÃLISIS MORFOLÃ“GICO ULTRA SENSIBLE")
print(f"   ğŸ‘¤ Usuario: Angel226m")
print(f"   ğŸ“… Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print(f"   ğŸ” DetecciÃ³n ultra sensible: grietas >= {Config.MIN_CRACK_LENGTH}px")
print("â•" * 100)

if cargar_modelo():
    print("âœ… Sistema listo para inferencia ultra sensible con anÃ¡lisis morfolÃ³gico")
else:
    print("âš ï¸  Servidor iniciado sin modelo")

print("â•" * 100)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=False)